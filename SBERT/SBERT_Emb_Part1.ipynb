{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "551d984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "pd.set_option('max_colwidth', None)\n",
    "pd.set_option(\"max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "011c281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../datasets/SDP_train.csv\")\n",
    "test_df  = pd.read_csv(\"../datasets/SDP_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef854dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>core_id</th>\n",
       "      <th>citing_title</th>\n",
       "      <th>citing_author</th>\n",
       "      <th>cited_title</th>\n",
       "      <th>cited_author</th>\n",
       "      <th>citation_context</th>\n",
       "      <th>citation_influence_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC1</td>\n",
       "      <td>158977742</td>\n",
       "      <td>Ontology-Based Recommendation of Editorial Products</td>\n",
       "      <td>Thiviyan Thanapalasingam</td>\n",
       "      <td>Web search personalization with ontological user profiles</td>\n",
       "      <td>Sieg</td>\n",
       "      <td>They usually generate user models that describe user interests according to a set of features #AUTHOR_TAG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC2</td>\n",
       "      <td>158977742</td>\n",
       "      <td>Ontology-Based Recommendation of Editorial Products</td>\n",
       "      <td>Thiviyan Thanapalasingam</td>\n",
       "      <td>Exploring Scholarly Data with Rexplore</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>The Computer Science Ontology (CSO)[3]is a large-scale and granular ontology of research topics that was created automatically by running the Klink-2 algorithm [1]on the Rexplore dataset #AUTHOR_TAG.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC3</td>\n",
       "      <td>158977742</td>\n",
       "      <td>Ontology-Based Recommendation of Editorial Products</td>\n",
       "      <td>Thiviyan Thanapalasingam</td>\n",
       "      <td>Klink-2: Integrating Multiple Web Sources to Generate Semantic Topic Networks</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>In order to do so, we characterized all SN publications according to their associated research topics by exploiting the Computer Science Ontology (CSO), a large-scale automatically generated taxonomy of research areas #AUTHOR_TAG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC4</td>\n",
       "      <td>158977742</td>\n",
       "      <td>Ontology-Based Recommendation of Editorial Products</td>\n",
       "      <td>Thiviyan Thanapalasingam</td>\n",
       "      <td>Forecasting the Spreading of Technologies in Research Communities</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>This API supports a number of applications, including Smart Book Recommender, Smart Topic Miner [5], the Technology-Topic Framework #AUTHOR_TAG, a system that forecasts the propagation of technologies across research communities, and the Pragmatic Ontology Evolution Framework [7], an approach to ontology evolution that is able to select new concepts on the basis of their contribution to specific computational tasks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC5</td>\n",
       "      <td>158977742</td>\n",
       "      <td>Ontology-Based Recommendation of Editorial Products</td>\n",
       "      <td>Thiviyan Thanapalasingam</td>\n",
       "      <td>Supporting Springer Nature Editors by means of Semantic Technologies</td>\n",
       "      <td>Osborne</td>\n",
       "      <td>It works according to three main steps:1) It represents journals, books, and conferences according to the metadata of their chapters/articles and uses the Smart Topic API #AUTHOR_TAG to characterize each of them with a semantically enhanced topic vector</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id    core_id                                         citing_title  \\\n",
       "0       CC1  158977742  Ontology-Based Recommendation of Editorial Products   \n",
       "1       CC2  158977742  Ontology-Based Recommendation of Editorial Products   \n",
       "2       CC3  158977742  Ontology-Based Recommendation of Editorial Products   \n",
       "3       CC4  158977742  Ontology-Based Recommendation of Editorial Products   \n",
       "4       CC5  158977742  Ontology-Based Recommendation of Editorial Products   \n",
       "\n",
       "              citing_author  \\\n",
       "0  Thiviyan Thanapalasingam   \n",
       "1  Thiviyan Thanapalasingam   \n",
       "2  Thiviyan Thanapalasingam   \n",
       "3  Thiviyan Thanapalasingam   \n",
       "4  Thiviyan Thanapalasingam   \n",
       "\n",
       "                                                                     cited_title  \\\n",
       "0                      Web search personalization with ontological user profiles   \n",
       "1                                         Exploring Scholarly Data with Rexplore   \n",
       "2  Klink-2: Integrating Multiple Web Sources to Generate Semantic Topic Networks   \n",
       "3              Forecasting the Spreading of Technologies in Research Communities   \n",
       "4           Supporting Springer Nature Editors by means of Semantic Technologies   \n",
       "\n",
       "  cited_author  \\\n",
       "0         Sieg   \n",
       "1      Osborne   \n",
       "2      Osborne   \n",
       "3      Osborne   \n",
       "4      Osborne   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                     citation_context  \\\n",
       "0                                                                                                                                                                                                                                                                                                                           They usually generate user models that describe user interests according to a set of features #AUTHOR_TAG   \n",
       "1                                                                                                                                                                                                                             The Computer Science Ontology (CSO)[3]is a large-scale and granular ontology of research topics that was created automatically by running the Klink-2 algorithm [1]on the Rexplore dataset #AUTHOR_TAG.   \n",
       "2                                                                                                                                                                                               In order to do so, we characterized all SN publications according to their associated research topics by exploiting the Computer Science Ontology (CSO), a large-scale automatically generated taxonomy of research areas #AUTHOR_TAG   \n",
       "3  This API supports a number of applications, including Smart Book Recommender, Smart Topic Miner [5], the Technology-Topic Framework #AUTHOR_TAG, a system that forecasts the propagation of technologies across research communities, and the Pragmatic Ontology Evolution Framework [7], an approach to ontology evolution that is able to select new concepts on the basis of their contribution to specific computational tasks   \n",
       "4                                                                                                                                                                       It works according to three main steps:1) It represents journals, books, and conferences according to the metadata of their chapters/articles and uses the Smart Topic API #AUTHOR_TAG to characterize each of them with a semantically enhanced topic vector   \n",
       "\n",
       "   citation_influence_label  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         1  \n",
       "4                         1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd3a777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['cited_text_all'] = train_df['citing_title'] + '.' +  train_df['cited_title'] + '.' + train_df['citation_context']\n",
    "#test_df['cited_text_all'] = test_df['citing_title'] + '.' + test_df['cited_title'] + '.' + test_df['citation_context']\n",
    "\n",
    "\n",
    "train_df['cited_text_all'] =  train_df['cited_title'] + '.' + train_df['citation_context']\n",
    "test_df['cited_text_all'] =  test_df['cited_title'] + '.' + test_df['citation_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8eb975d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                               Web search personalization with ontological user profiles.They usually generate user models that describe user interests according to a set of features #AUTHOR_TAG\n",
       "1    Exploring Scholarly Data with Rexplore.The Computer Science Ontology (CSO)[3]is a large-scale and granular ontology of research topics that was created automatically by running the Klink-2 algorithm [1]on the Rexplore dataset #AUTHOR_TAG.\n",
       "Name: cited_text_all, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['cited_text_all'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fc40be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'They usually generate user models that describe user interests according to a set of features  '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s='They usually generate user models that describe user interests according to a set of features #AUTHOR_TAG'\n",
    "s.replace('#AUTHOR_TAG', ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dba0f0",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60c21a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1559e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessor import Preprocessing\n",
    "preprocessed_data = []\n",
    "pre = Preprocessing()\n",
    "\n",
    "train_df['cited_text_all_cleaned'] = train_df['cited_text_all'].apply(lambda x:pre.preprocess(x))\n",
    "train_df['cited_text_all_cleaned'] = train_df['cited_text_all_cleaned'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a18dd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['cited_text_all_cleaned'] = test_df['cited_text_all'].apply(lambda x:pre.preprocess(x))\n",
    "test_df['cited_text_all_cleaned'] = test_df['cited_text_all_cleaned'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8f469fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the english village community examined relation manorial tribal system common open field system husbandry essay economic history.in historical research , regressive method moving step-by-step back time better known later situation already applied bloch reconstruction medieval agrarian landscape france used since within historical research\n",
       "1                                                                                                                                        die italienischen begr nder der wiener donaukartographie.for example , new cut-off channel donaukanal excavated 1700-1703 bridge built 1704 later added , could serve basis proposed hydraulic construction 1712\n",
       "Name: cited_text_all_cleaned, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['cited_text_all_cleaned'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3a0c0a",
   "metadata": {},
   "source": [
    "### Build embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c512857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "122b2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELNAME = 'all-mpnet-base-v2'\n",
    "# 'quora-distilbert-base' time to build emb 225.0789451599121 seconds\n",
    "# 'all-mpnet-base-v2'     Time to build emb 482.\n",
    "model = SentenceTransformer(MODELNAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feea2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Building embeddings\")\n",
    "# start = time.time()\n",
    "# encoded_data = model.encode(train_df['cited_text_all'].tolist())\n",
    "# encoded_data = np.asarray(encoded_data.astype('float32'))\n",
    "# end = time.time()\n",
    "# print(\"Time to build emb {} seconds\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86df8b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dim_0', 'dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_6', 'dim_7', 'dim_8', 'dim_9']\n"
     ]
    }
   ],
   "source": [
    "colnames = [\"dim_\" + str(i) for i in range(0,768)]\n",
    "print(colnames[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43712dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22f0d850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df['cited_emb_all'] = train_df['cited_text_all'].apply(lambda x:model.encode(x)) \n",
    "emb_df = pd.DataFrame(train_df['cited_emb_all'].to_list(), columns = colnames)\n",
    "train_df 2= pd.concat([train_df,emb_df],axis=1)\n",
    "train_df.to_pickle('../datasets/SDP_train_and_emb_mpnet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db602f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['cited_emb_all'] = test_df['cited_text_all'].apply(lambda x:model.encode(x)) \n",
    "emb_df = pd.DataFrame(test_df['cited_emb_all'].to_list(), columns = colnames)\n",
    "test_df = pd.concat([test_df,emb_df],axis=1)\n",
    "test_df.to_pickle('../datasets/SDP_test_and_emb_mpnet.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4ed6efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 779)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
